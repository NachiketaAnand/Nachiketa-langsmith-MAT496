{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders.sitemap import SitemapLoader\n",
        "from langchain_community.vectorstores import SKLearnVectorStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "def get_vector_db_retriever():\n",
        "    persist_path = os.path.join(tempfile.gettempdir(), \"union.parquet\")\n",
        "    embd = OpenAIEmbeddings()\n",
        "\n",
        "    # If vector store exists, then load it\n",
        "    if os.path.exists(persist_path):\n",
        "        vectorstore = SKLearnVectorStore(\n",
        "            embedding=embd,\n",
        "            persist_path=persist_path,\n",
        "            serializer=\"parquet\"\n",
        "        )\n",
        "        return vectorstore.as_retriever(lambda_mult=0)\n",
        "\n",
        "    # Otherwise, index LangSmith documents and create new vector store\n",
        "    ls_docs_sitemap_loader = SitemapLoader(web_path=\"https://docs.smith.langchain.com/sitemap.xml\", continue_on_failure=True)\n",
        "    ls_docs = ls_docs_sitemap_loader.load()\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "        chunk_size=500, chunk_overlap=0\n",
        "    )\n",
        "    doc_splits = text_splitter.split_documents(ls_docs)\n",
        "\n",
        "    vectorstore = SKLearnVectorStore.from_documents(\n",
        "        documents=doc_splits,\n",
        "        embedding=embd,\n",
        "        persist_path=persist_path,\n",
        "        serializer=\"parquet\"\n",
        "    )\n",
        "    vectorstore.persist()\n",
        "    return vectorstore.as_retriever(lambda_mult=0)\n"
      ],
      "metadata": {
        "id": "IRDPqhKt5yjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\""
      ],
      "metadata": {
        "id": "eP3Gg5vMhmg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langgraph-sdk langgraph-checkpoint-sqlite \"langsmith>=0.2.0\" langchain-community langchain-core langchain-openai notebook python-dotenv lxml scikit-learn pandas pyarrow utils\n"
      ],
      "metadata": {
        "id": "MTH-1EGwiLyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import traceable\n",
        "from openai import OpenAI\n",
        "from typing import List\n",
        "import nest_asyncio\n",
        "from utils import get_vector_db_retriever\n",
        "\n",
        "\n",
        "MODEL_PROVIDER = \"openai\"\n",
        "MODEL_NAME = \"gpt-4o-mini\"\n",
        "APP_VERSION = 1.0\n",
        "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the latest question in the conversation.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Use three sentences maximum and keep the answer concise.\n",
        "\"\"\"\n",
        "\n",
        "openai_client = OpenAI()\n",
        "nest_asyncio.apply()\n",
        "retriever = get_vector_db_retriever()\n",
        "\n",
        "\"\"\"\n",
        "retrieve_documents\n",
        "- Returns documents fetched from a vectorstore based on the user's question\n",
        "\"\"\"\n",
        "@traceable(run_type=\"chain\")\n",
        "def retrieve_documents(question: str):\n",
        "    return retriever.invoke(question)\n",
        "\n",
        "\"\"\"\n",
        "generate_response\n",
        "- Calls `call_openai` to generate a model response after formatting inputs\n",
        "\"\"\"\n",
        "@traceable(run_type=\"chain\")\n",
        "def generate_response(question: str, documents):\n",
        "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": RAG_SYSTEM_PROMPT\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
        "        }\n",
        "    ]\n",
        "    return call_openai(messages)\n",
        "\n",
        "\"\"\"\n",
        "call_openai\n",
        "- Returns the chat completion output from OpenAI\n",
        "\"\"\"\n",
        "@traceable(run_type=\"llm\")\n",
        "def call_openai(\n",
        "    messages: List[dict], model: str = MODEL_NAME, temperature: float = 0.0\n",
        ") -> str:\n",
        "    return openai_client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "\n",
        "\"\"\"\n",
        "langsmith_rag\n",
        "- Calls `retrieve_documents` to fetch documents\n",
        "- Calls `generate_response` to generate a response based on the fetched documents\n",
        "- Returns the model response\n",
        "\"\"\"\n",
        "@traceable(run_type=\"chain\")\n",
        "def langsmith_rag(question: str):\n",
        "    documents = retrieve_documents(question)\n",
        "    response = generate_response(question, documents)\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "7yqr25zhhu6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who is Elon Musk?\"\n",
        "ai_answer = langsmith_rag(question, langsmith_extra={\"metadata\": {\"website\": \"www.google.com\"}})\n",
        "print(ai_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCO3mNXy6Njj",
        "outputId": "31f64926-d2f6-4b91-a4ac-f3ac00a822ef"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elon Musk is a billionaire entrepreneur and business magnate known for founding and leading several high-profile technology companies, including Tesla, SpaceX, Neuralink, and The Boring Company. He is recognized for his work in advancing electric vehicles, space exploration, and renewable energy. Musk is also known for his influential presence on social media and his ambitious vision for the future, including plans for Mars colonization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mj_WzgvW8evd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E3zEyF5G6NVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "hlLKZ8PJ88y6"
      }
    }
  ]
}